material {
    name : sao,
    parameters : [
        {
            type : sampler2d,
            name : depth,
            precision: high
        },
        {
            type : mat4,
            name : screenFromViewMatrix
        },
        {
            type : float4,
            name : resolution,
            precision: high
        },
        {
            type : float2,
            name : positionParams,
            precision: high
        },
        {
            type : float,
            name : depthParams,
            precision: high
        },
        {
            type : float,
            name : invRadiusSquared
        },
        {
            type : float,
            name : minHorizonAngleSineSquared
        },
        {
            type : float,
            name : peak2
        },
        {
            type : float,
            name : projectionScale
        },
        {
            type : float,
            name : projectionScaleRadius
        },
        {
            type : float,
            name : bias
        },
        {
            type : float,
            name : power
        },
        {
            type : float,
            name : intensity
        },
        {
            type : float,
            name : spiralTurns
        },
        {
            type : float2,
            name : sampleCount
        },
        {
            type : float2,
            name : angleIncCosSin
        },
        {
            type : float,
            name : invFarPlane
        },
        {
            type : int,
            name : maxLevel
        },
        {
            type : float2,
            name : reserved
        },
        {
            type : float,
            name : ssctShadowDistance
        },
        {
            type : float,
            name : ssctConeAngleTangeant
        },
        {
            type : float,
            name : ssctContactDistanceMaxInv
        },
        {
            type : float3,
            name : ssctVsLightDirection
        },
        {
            type : float,
            name : ssctIntensity
        },
        {
            type : float2,
            name : ssctDepthBias
        },
        {
            type : float2,
            name : ssctRayCount
        },
        {
            type : uint,
            name : ssctSampleCount
        }
    ],
    variables : [
         vertex
    ],
    domain : postprocess,
    depthWrite : false,
    depthCulling : true
}

vertex {
    void postProcessVertex(inout PostProcessVertexInputs postProcess) {
        postProcess.vertex.xy = postProcess.normalizedUV;
    }
}

fragment {
    #include "ssaoUtils.fs"
    #include "ssct.fs"

    const float kLog2LodRate = 3.0;

    vec2 sq(const vec2 a) {
        return a * a;
    }

    vec2 pack(highp float depth) {
        // we need 16-bits of precision
        highp float z = clamp(depth * materialParams.invFarPlane, 0.0, 1.0);
        highp float t = floor(256.0 * z);
        mediump float hi = t * (1.0 / 256.0);   // we only need 8-bits of precision
        mediump float lo = (256.0 * z) - t;     // we only need 8-bits of precision
        return vec2(hi, lo);
    }

    // random number between 0 and 1, using interleaved gradient noise
    float random(const highp vec2 w) {
        const vec3 m = vec3(0.06711056, 0.00583715, 52.9829189);
        return fract(m.z * fract(dot(w, m.xy)));
    }

    highp vec2 getApiAgnosticFragCoords() {
#if defined(TARGET_METAL_ENVIRONMENT) || defined(TARGET_VULKAN_ENVIRONMENT)
        return vec2(gl_FragCoord.x, materialParams.resolution.y - gl_FragCoord.y);
#else
        return gl_FragCoord.xy;
#endif
    }

    highp vec3 computeViewSpacePositionFromDepth(highp vec2 ss, highp float linearDepth) {
        return vec3((0.5 - ss) * materialParams.positionParams.xy * linearDepth, linearDepth);
    }

    highp vec3 faceNormal(highp vec3 dpdx, highp vec3 dpdy) {
        return normalize(cross(dpdx, dpdy));
    }

    // Compute normals using derivatives, which essentially results in half-resolution normals
    // this creates arifacts around geometry edges.
    // Note: when using the spirv optimizer, this results in much slower execution time because
    //       this whole expression is inlined in the AO loop below.
    highp vec3 computeViewSpaceNormal(const highp vec3 position) {
        return faceNormal(dFdx(position), dFdy(position));
    }

    // Compute normals directly from the depth texture, resulting in full resolution normals
    // Note: This is actually as cheap as using derivatives because the texture fetches
    //       are essentially equivalent to textureGather (which we don't have on ES3.0),
    //       and this is executed just once.
    highp vec3 computeViewSpaceNormal(const highp vec3 position, const highp vec2 uv) {
        highp vec2 ss = ssFromUv(uv);
        highp vec2 ssdx = ss + vec2(materialParams.resolution.z, 0.0);
        highp vec2 ssdy = ss + vec2(0.0, materialParams.resolution.w);
        highp vec3 px = computeViewSpacePositionFromDepth(ssdx,
                sampleDepthLinear(materialParams_depth, uvFromSs(ssdx), 0.0, materialParams.depthParams));
        highp vec3 py = computeViewSpacePositionFromDepth(ssdy,
                sampleDepthLinear(materialParams_depth, uvFromSs(ssdy), 0.0, materialParams.depthParams));
        highp vec3 dpdx = px - position;
        highp vec3 dpdy = py - position;
        return faceNormal(dpdx, dpdy);
    }

    // Ambient Occlusion, largely inspired from:
    // "The Alchemy Screen-Space Ambient Obscurance Algorithm" by Morgan McGuire
    // "Scalable Ambient Obscurance" by Morgan McGuire, Michael Mara and David Luebke

    vec3 tapLocation(float i, const float noise) {
        float offset = ((2.0 * PI) * 2.4) * noise;
        float angle = ((i * materialParams.sampleCount.y) * materialParams.spiralTurns) * (2.0 * PI) + offset;
        float radius = (i + noise + 0.5) * materialParams.sampleCount.y;
        return vec3(cos(angle), sin(angle), radius * radius);
    }

    highp vec2 startPosition(const float noise) {
        float angle = ((2.0 * PI) * 2.4) * noise;
        return vec2(cos(angle), sin(angle));
    }

    highp mat2 tapAngleStep() {
        highp vec2 t = materialParams.angleIncCosSin;
        return mat2(t.x, t.y, -t.y, t.x);
    }

    vec3 tapLocationFast(float i, vec2 p, const float noise) {
        float radius = (i + noise + 0.5) * materialParams.sampleCount.y;
        return vec3(p, radius * radius);
    }


    void computeAmbientOcclusionSAO(inout float occlusion, float i, float ssDiskRadius,
            const highp vec2 uv,  const highp vec3 origin, const vec3 normal,
            const vec2 tapPosition, const float noise) {

        highp vec2 ss = ssFromUv(uv);

        vec3 tap = tapLocationFast(i, tapPosition, noise);

        float ssRadius = max(1.0, tap.z * ssDiskRadius); // at least 1 pixel screen-space radius

        vec2 ssSamplePos = ss + vec2(ssRadius * tap.xy) * materialParams.resolution.zw;

        float level = clamp(floor(log2(ssRadius)) - kLog2LodRate, 0.0, float(materialParams.maxLevel));
        highp float occlusionDepth = sampleDepthLinear(materialParams_depth, uvFromSs(ssSamplePos), level, materialParams.depthParams);
        highp vec3 p = computeViewSpacePositionFromDepth(ssSamplePos, occlusionDepth);

        // now we have the sample, compute AO
        vec3 v = p - origin;        // sample vector
        float vv = dot(v, v);       // squared distance
        float vn = dot(v, normal);  // distance * cos(v, normal)

        // discard samples that are outside of the radius, preventing distant geometry to
        // cast shadows -- there are many functions that work and choosing one is an artistic
        // decision.
        float w = sq(max(0.0, 1.0 - vv * materialParams.invRadiusSquared));

        // discard samples that are too close to the horizon to reduce shadows cast by geometry
        // not sufficently tessellated. The goal is to discard samples that form an angle 'beta'
        // smaller than 'epsilon' with the horizon. We already have dot(v,n) which is equal to the
        // sin(beta) * |v|. So the test simplifies to vn^2 < vv * sin(epsilon)^2.
        w *= step(vv * materialParams.minHorizonAngleSineSquared, vn * vn);

        occlusion += w * max(0.0, vn + origin.z * materialParams.bias) / (vv + materialParams.peak2);
    }

    float scalableAmbientObscurance(highp vec2 uv, highp vec3 origin, vec3 normal) {
        float noise = random(getApiAgnosticFragCoords());
        highp vec2 tapPosition = startPosition(noise);
        highp mat2 angleStep = tapAngleStep();

        // Choose the screen-space sample radius
        // proportional to the projected area of the sphere
        float ssDiskRadius = -(materialParams.projectionScaleRadius / origin.z);

        float occlusion = 0.0;
        for (float i = 0.0; i < materialParams.sampleCount.x; i += 1.0) {
            computeAmbientOcclusionSAO(occlusion, i, ssDiskRadius, uv, origin, normal, tapPosition, noise);
            tapPosition = angleStep * tapPosition;
        }
        return sqrt(occlusion * materialParams.intensity);
    }

    float dominantLightShadowing(highp vec2 uv, highp vec3 origin, vec3 normal) {
        ConeTraceSetup cone;

        cone.ssStartPos = ssFromUv(uv) * materialParams.resolution.xy;
        cone.vsStartPos = origin;
        cone.vsNormal = normal;

        cone.vsConeDirection = materialParams.ssctVsLightDirection;
        cone.shadowDistance = materialParams.ssctShadowDistance;
        cone.coneAngleTangeant = materialParams.ssctConeAngleTangeant;
        cone.contactDistanceMaxInv = materialParams.ssctContactDistanceMaxInv;

        cone.screenFromViewMatrix = materialParams.screenFromViewMatrix;
        cone.depthParams = materialParams.depthParams;
        cone.projectionScale = materialParams.projectionScale;
        cone.resolution = materialParams.resolution;
        cone.maxLevel = float(materialParams.maxLevel);

        cone.intensity = materialParams.ssctIntensity;
        cone.depthBias = materialParams.ssctDepthBias.x;
        cone.slopeScaledDepthBias = materialParams.ssctDepthBias.y;
        cone.sampleCount = materialParams.ssctSampleCount;

        float occlusion = 0.0;
        for (float i = 1.0; i <= materialParams.ssctRayCount.x; i += 1.0) {
            cone.jitterOffset.x = random(getApiAgnosticFragCoords() * i) * 2.0 - 1.0;      // direction
            cone.jitterOffset.y = random(getApiAgnosticFragCoords() * i * vec2(3, 11));    // step
            occlusion += coneTraceOcclusion(cone, materialParams_depth);
        }
        return occlusion * materialParams.ssctRayCount.y;
    }

    // For SAO calculations, we make use of two coordinate spaces:
    //     UV-space: framebuffer/texture space, graphics API dependent.
    //     screen-space: origin bottom left, normalized coordinates.
    // Textures must always be sampled with UV coordinates.

    void postProcess(inout PostProcessInputs postProcess) {
        highp vec2 uv = variable_vertex.xy; // interpolated to pixel center

        highp float depth = sampleDepthLinear(materialParams_depth, uv, 0.0, materialParams.depthParams);
        highp vec3 origin = computeViewSpacePositionFromDepth(ssFromUv(uv), depth);
        vec3 normal = computeViewSpaceNormal(origin, uv);

        float occlusion = 0.0;

        if (materialParams.intensity > 0.0) {
            occlusion = scalableAmbientObscurance(uv, origin, normal);
        }

        if (materialParams.ssctIntensity > 0.0) {
            occlusion = max(occlusion, dominantLightShadowing(uv, origin, normal));
        }

        // occlusion to visibility
        float aoVisibility = pow(saturate(1.0 - occlusion), materialParams.power);

#if defined(TARGET_MOBILE)
        // this line is needed to workaround what seems to be a bug on qualcomm hardware
        aoVisibility += getApiAgnosticFragCoords().x * MEDIUMP_FLT_MIN;
#endif

        postProcess.color.rgb = vec3(aoVisibility, pack(origin.z));
    }
}
