material {
    name : ssao,
    parameters : [
        {
            type : sampler2d,
            name : depth,
            precision: high
        },
        {
            type : float4,
            name : resolution
        },
        {
            type : float,
            name : radius
        },
        {
            type : float,
            name : invRadiusSquared
        },
        {
            type : float,
            name : projectionScaleRadius
        },
        {
            type : float,
            name : bias
        },
        {
            type : float,
            name : power
        },
        {
            type : int,
            name : maxLevel
        }
    ],
    variables : [
         vertex
    ],
    vertexDomain : device,
    depthWrite : false,
    depthCulling : true,
    shadingModel : unlit,
    variantFilter : [ skinning, shadowReceiver ]
}

vertex {
    void materialVertex(inout MaterialVertexInputs material) {
        // far-plane in view space
        vec4 position = getPosition(); // clip-space
        material.vertex.xy = (position.xy * 0.5 + 0.5);
        material.vertex.zw = position.xy;
    }
}

fragment {
    #define NOISE_NONE      0
    #define NOISE_PATTERN   1
    #define NOISE_RANDOM    2
    #define NOISE_TYPE      NOISE_PATTERN

    const uint kSphereSampleCount = 16u;
    const vec3 kSphereSamples[] = vec3[](
        vec3(-1.60954e-06,  3.93118e-07,  1.51895e-06), vec3(-0.09508890,  0.00458908, -0.0312535),
        vec3( 0.015179900, -0.025586400,  0.003764530), vec3( 0.07342620,  0.02180220,  0.0027781),
        vec3( 0.094587400,  0.043218400,  0.089147500), vec3(-0.00950861,  0.05136860,  0.0196730),
        vec3( 0.139973000, -0.101685000,  0.108570000), vec3(-0.10380400,  0.21985300, -0.0430164),
        vec3( 0.004840530, -0.033987800,  0.094186800), vec3( 0.02801140,  0.05846620, -0.2571100),
        vec3(-0.051030600,  0.074993000,  0.259843000), vec3( 0.11882200, -0.18653700, -0.1341920),
        vec3( 0.063949400, -0.094893600, -0.072683000), vec3( 0.10817600,  0.32710800, -0.2540580),
        vec3(-0.047179600,  0.219180000,  0.263895000), vec3(-0.40770900,  0.24083400, -0.2003520)
    );

    const uint kNoiseSampleCount = 16u;
    const vec3 kNoiseSamples[] = vec3[](
        vec3(-0.0782473, -0.749924, -0.6568800), vec3(-0.5723190, -0.1023790, -0.813615),
        vec3( 0.0486527, -0.380791,  0.9233800), vec3( 0.2812020, -0.6566640, -0.699799),
        vec3( 0.7119110, -0.235841, -0.6614850), vec3(-0.4458930,  0.6110630,  0.654050),
        vec3(-0.7035980,  0.674837,  0.2225870), vec3( 0.7682360,  0.5074570,  0.390257),
        vec3(-0.6702860, -0.470387,  0.5739800), vec3( 0.1992350,  0.8493360, -0.488808),
        vec3(-0.7680680, -0.583633, -0.2635200), vec3(-0.8973300,  0.3288530,  0.294372),
        vec3(-0.5709300, -0.531056, -0.6261140), vec3( 0.6990140,  0.0632826, -0.712303),
        vec3( 0.2074950,  0.976129, -0.0641723), vec3(-0.0609008, -0.8697380, -0.489742)
    );

    // random number between 0 and 1
    float random(highp vec2 n) {
        n  = fract(n * vec2(5.3987, 5.4421));
        n += dot(n.yx, n.xy + vec2(21.5351, 14.3137));
        highp float xy = n.x * n.y;
        // compute in [0..2[ and remap to [0.0..1.0[
        return fract(xy * 95.4307) + fract(xy * 75.04961) * 0.5;
    }

    // noise vector between -1 and 1
    vec3 getNoise(const vec2 uv) {
        #if NOISE_TYPE == NOISE_RANDOM
            return normalize(2.0 * vec3(random(uv), random(uv * 2.0), random(uv * 4.0)) - vec3(1.0));
        #elif NOISE_TYPE == NOISE_PATTERN
            uint ix = uint(gl_FragCoord.x) & 3u;
            uint iy = uint(gl_FragCoord.y) & 3u;
            return kNoiseSamples[ix + iy * 4u];
        #else
            return vec3(0.0);
        #endif
    }

    highp float linearizeDepth(highp float depth) {
        highp mat4 projection = getClipFromViewMatrix();
        highp float z = depth * 2.0 - 1.0; // depth in clip space
        return -projection[3].z / (z + projection[2].z);
    }

    highp float sampleDepthLinear(const vec2 uv) {
        return linearizeDepth(texture(materialParams_depth, uv, 0.0).r);
    }

    highp vec3 computeViewSpacePositionFromDepth(in vec2 p, highp float linearDepth) {
        p = p * 2.0 - 1.0; // to clip space
        highp mat4 invProjection = getViewFromClipMatrix();
        p.x *= invProjection[0].x;
        p.y *= invProjection[1].y;
        return vec3(p * -linearDepth, linearDepth);
    }

    // compute normals using derivatives, which essentially results in half-resolution normals
    // this creates arifacts around geometry edges
    highp vec3 computeViewSpaceNormalNotNormalized(const highp vec3 position) {
        highp vec3 dpdx = dFdx(position);
        highp vec3 dpdy = dFdy(position);
        return cross(dpdx, dpdy);
    }

    // compute normals directly from the depth texture, resulting in full resolution normals
    highp vec3 computeViewSpaceNormalNotNormalized(const highp vec3 position, const vec2 uv) {
        vec2 uvdx = uv + vec2(materialParams.resolution.z, 0.0);
        vec2 uvdy = uv + vec2(0.0, materialParams.resolution.w);
        highp vec3 px = computeViewSpacePositionFromDepth(uvdx, sampleDepthLinear(uvdx));
        highp vec3 py = computeViewSpacePositionFromDepth(uvdy, sampleDepthLinear(uvdy));
        highp vec3 dpdx = px - position;
        highp vec3 dpdy = py - position;
        return cross(dpdx, dpdy);
    }

    // Ambient Occlusion, largely inspired from:
    // Hemisphere Crysis-style SSAO. See "Screen Space Ambient Occlusion" by John Chapman

    float computeAmbientOcclusionSSAO(const highp vec3 origin, const vec3 normal, const vec3 noise, const vec3 sphereSample) {
        highp mat4 projection = getClipFromViewMatrix();
        float radius = materialParams.radius;
        float bias = materialParams.bias;

        vec3 r = sphereSample * radius;
        r = reflect(r, noise);
        r = sign(dot(r, normal)) * r;
        highp vec3 samplePos = origin + r;

        highp vec4 samplePosScreen = projection * vec4(samplePos, 1.0);
        samplePosScreen.xy = samplePosScreen.xy * (0.5 / samplePosScreen.w) + 0.5;

        highp float occlusionDepth = sampleDepthLinear(samplePosScreen.xy);

        // smoothstep() optimized for range 0 to 1
        float t = saturate(radius / abs(origin.z - occlusionDepth));
        float rangeCheck = t * t * (3.0 - 2.0 * t);
        float d = samplePos.z - occlusionDepth; // distance from depth to sample
        return (d >= -bias ? 0.0 : rangeCheck);
    }

    void material(inout MaterialInputs material) {
        prepareMaterial(material);

        vec2 uv = variable_vertex.xy; // interpolated to pixel center

        highp float depth = sampleDepthLinear(uv);
        highp vec3 origin = computeViewSpacePositionFromDepth(uv, depth);
        highp vec3 normal = computeViewSpaceNormalNotNormalized(origin, uv);

        normal = normalize(normal);
        vec3 noise = getNoise(uv);

        float occlusion = 0.0;
        for (uint i = 0u; i < kSphereSampleCount; i++) {
            occlusion += computeAmbientOcclusionSSAO(origin, normal, noise, kSphereSamples[i]);
        }

        float ao = 1.0 - occlusion / float(kSphereSampleCount);
        // simulate user-controled ao^n with n[1, 2]
        ao = mix(ao, ao * ao, materialParams.power);

        material.baseColor.r = ao;
    }
}
