material {
    name : taa,
    parameters : [
        {
            type : sampler2d,
            name : color
        },
        {
            type : sampler2d,
            name : depth,
            precision: high
        },
        {
            type : float,
            name : alpha
        },
        {
            type : sampler2d,
            name : history
        },
        {
            type : mat4,
            name : reprojection,
            precision: high
        },
        {
            type : float2,
            name : jitter,
            precision: high
        },
        {
            type : float4[9],
            name : filterWeights
        }
    ],
    constants : [
        {
            type : bool,
            name : historyReprojection,
            default : true
        },
        {
            type : bool,
            name : filterHistory,
            default : true
        },
        {
            type : bool,
            name : filterInput,
            default : true
        },
        {
            type : int,
            name : boxClipping,
            default : 0
        },
        {
            type : int,
            name : boxType,
            default : 1
        },
        {
            type : bool,
            name : useYCoCg,
            default : false
        },
        {
            type : bool,
            name : preventFlickering,
            default : false
        },
        {
            type : float,
            name : varianceGamma,
            default : 1.0
        }
    ],
    variables : [
        vertex
    ],
    domain : postprocess,
    depthWrite : false,
    depthCulling : false
}

vertex {
    void postProcessVertex(inout PostProcessVertexInputs postProcess) {
        postProcess.vertex.xy = uvToRenderTargetUV(postProcess.normalizedUV);
    }
}

fragment {

/* Clipping box type */

// min/max neighborhood
#define BOX_TYPE_AABB           0
// Variance based neighborhood
#define BOX_TYPE_VARIANCE       1
// uses both min/max and variance
#define BOX_TYPE_AABB_VARIANCE  2

/* Clipping algorithm */

// accurate box clipping
#define BOX_CLIPPING_ACCURATE   0
// clamping instead of clipping
#define BOX_CLIPPING_CLAMP      1
// no clipping (for debugging only)
#define BOX_CLIPPING_NONE       2

float luma(const vec3 color) {
    if (materialConstants_useYCoCg) {
        return color.x;
    } else {
        return luminance(color);
    }
}

vec3 RGB_YCoCg(const vec3 c) {
    float Y  = dot(c.rgb, vec3( 1, 2,  1) * 0.25);
    float Co = dot(c.rgb, vec3( 2, 0, -2) * 0.25);
    float Cg = dot(c.rgb, vec3(-1, 2, -1) * 0.25);
    return vec3(Y, Co, Cg);
}

vec3 YCoCg_RGB(const vec3 c) {
    float Y  = c.x;
    float Co = c.y;
    float Cg = c.z;
    float r = Y + Co - Cg;
    float g = Y + Cg;
    float b = Y - Co - Cg;
    return vec3(r, g, b);
}

// clip the (c, h) segment to a box
vec4 clipToBox(const int quality,
        const vec3 boxmin,  const vec3 boxmax, const vec4 c, const vec4 h) {
    const float epsilon = 0.0001;

    if (quality == BOX_CLIPPING_ACCURATE) {
        vec4 r = c - h;
        vec3 ir = 1.0 / (epsilon + r.rgb);
        vec3 rmax = (boxmax - h.rgb) * ir;
        vec3 rmin = (boxmin - h.rgb) * ir;
        vec3 imin = min(rmax, rmin);
        return h + r * saturate(max3(imin));
    } else if (quality == BOX_CLIPPING_CLAMP) {
        return vec4(clamp(h.rgb, boxmin, boxmax), h.a);
    }
    return h;
}

// Samples a texture with Catmull-Rom filtering, using 9 texture fetches instead of 16.
//      https://therealmjp.github.io/
// Some optimizations from here:
//      http://vec3.ca/bicubic-filtering-in-fewer-taps/ for more details
// Optimized to 5 taps by removing the corner samples
// And modified for mediump support
vec4 sampleTextureCatmullRom(const sampler2D tex, const highp vec2 uv, const highp vec2 texSize) {
    // We're going to sample a a 4x4 grid of texels surrounding the target UV coordinate. We'll do this by rounding
    // down the sample location to get the exact center of our "starting" texel. The starting texel will be at
    // location [1, 1] in the grid, where [0, 0] is the top left corner.

    highp vec2 samplePos = uv * texSize;
    highp vec2 texPos1 = floor(samplePos - 0.5) + 0.5;

    // Compute the fractional offset from our starting texel to our original sample location, which we'll
    // feed into the Catmull-Rom spline function to get our filter weights.
    highp vec2 f = samplePos - texPos1;
    highp vec2 f2 = f * f;
    highp vec2 f3 = f2 * f;

    // Compute the Catmull-Rom weights using the fractional offset that we calculated earlier.
    // These equations are pre-expanded based on our knowledge of where the texels will be located,
    // which lets us avoid having to evaluate a piece-wise function.
    vec2 w0 = f2 - 0.5 * (f3 + f);
    vec2 w1 = 1.5 * f3 - 2.5 * f2 + 1.0;
    vec2 w3 = 0.5 * (f3 - f2);
    vec2 w2 = 1.0 - w0 - w1 - w3;

    // Work out weighting factors and sampling offsets that will let us use bilinear filtering to
    // simultaneously evaluate the middle 2 samples from the 4x4 grid.
    vec2 w12 = w1 + w2;

    // Compute the final UV coordinates we'll use for sampling the texture
    highp vec2 texPos0 = texPos1 - vec2(1.0);
    highp vec2 texPos3 = texPos1 + vec2(2.0);
    highp vec2 texPos12 = texPos1 + w2 / w12;

    highp vec2 invTexSize = 1.0 / texSize;
    texPos0  *= invTexSize;
    texPos3  *= invTexSize;
    texPos12 *= invTexSize;

    float k0 = w12.x * w0.y;
    float k1 = w0.x  * w12.y;
    float k2 = w12.x * w12.y;
    float k3 = w3.x  * w12.y;
    float k4 = w12.x * w3.y;

    vec4 result =   textureLod(tex, vec2(texPos12.x, texPos0.y),  0.0) * k0
                  + textureLod(tex, vec2(texPos0.x,  texPos12.y), 0.0) * k1
                  + textureLod(tex, vec2(texPos12.x, texPos12.y), 0.0) * k2
                  + textureLod(tex, vec2(texPos3.x,  texPos12.y), 0.0) * k3
                  + textureLod(tex, vec2(texPos12.x, texPos3.y),  0.0) * k4;

    result *= 1.0 / (k0 + k1 + k2 + k3 + k4);

    // we could end-up with negative values
    result = max(vec4(0), result);

    return result;
}

void postProcess(inout PostProcessInputs postProcess) {
    highp vec4 uv = variable_vertex.xyxy; // interpolated to pixel center

    if (materialConstants_historyReprojection) {
        // read the depth buffer center sample for reprojection
        highp float depth = textureLod(materialParams_depth, uv.xy, 0.0).r;
        // reproject history to current frame
        uv.zw = uvToRenderTargetUV(uv.zw);
        highp vec4 q = materialParams.reprojection * vec4(uv.zw, depth, 1.0);
        uv.zw = (q.xy * (1.0 / q.w)) * 0.5 + 0.5;
        uv.zw = uvToRenderTargetUV(uv.zw);
    }

    // read center color and history samples
    vec4 history;
    if (materialConstants_filterHistory) {
        history = sampleTextureCatmullRom(materialParams_history, uv.zw,
                vec2(textureSize(materialParams_history, 0)));
    } else {
        history = textureLod(materialParams_history, uv.zw, 0.0);
    }

    if (materialConstants_useYCoCg) {
        history.rgb = RGB_YCoCg(history.rgb);
    }

    highp vec2 p = uv.xy;
    vec4 color = textureLod(materialParams_color, p, 0.0);

    vec3 s[9];
    if (materialConstants_filterInput || materialConstants_boxClipping != BOX_CLIPPING_NONE) {
        s[0] = textureLodOffset(materialParams_color, p, 0.0, ivec2(-1, -1)).rgb;
        s[1] = textureLodOffset(materialParams_color, p, 0.0, ivec2( 0, -1)).rgb;
        s[2] = textureLodOffset(materialParams_color, p, 0.0, ivec2( 1, -1)).rgb;
        s[3] = textureLodOffset(materialParams_color, p, 0.0, ivec2(-1,  0)).rgb;
        s[4] = color.rgb;
        s[5] = textureLodOffset(materialParams_color, p, 0.0, ivec2( 1,  0)).rgb;
        s[6] = textureLodOffset(materialParams_color, p, 0.0, ivec2(-1,  1)).rgb;
        s[7] = textureLodOffset(materialParams_color, p, 0.0, ivec2( 0,  1)).rgb;
        s[8] = textureLodOffset(materialParams_color, p, 0.0, ivec2( 1,  1)).rgb;
    }

    if (materialConstants_useYCoCg) {
        color.rgb = RGB_YCoCg(color.rgb);
        if (materialConstants_filterInput || materialConstants_boxClipping != BOX_CLIPPING_NONE) {
            for (int i = 0; i < 9; i++) {
                s[i] = RGB_YCoCg(s[i]);
            }
        }
    }

    vec4 filtered;
    if (materialConstants_filterInput) {
        // unjitter/filter input
        filtered = vec4(0, 0, 0, color.a);
        for (int i = 0; i < 9; i++) {
            filtered.rgb += s[i] * materialParams.filterWeights[i][0];
        }
    } else {
        filtered = color;
    }

    // build the history clamping box
    if (materialConstants_boxClipping != BOX_CLIPPING_NONE) {
        vec3 boxmin;
        vec3 boxmax;
        if (materialConstants_boxType == BOX_TYPE_AABB ||
                materialConstants_boxType == BOX_TYPE_AABB_VARIANCE) {
            boxmin = min(s[4], min(min(s[1], s[3]), min(s[5], s[7])));
            boxmax = max(s[4], max(max(s[1], s[3]), max(s[5], s[7])));
            vec3 box9min = min(boxmin, min(min(s[0], s[2]), min(s[6], s[8])));
            vec3 box9max = max(boxmax, max(max(s[0], s[2]), max(s[6], s[8])));
            // round the corners of the 3x3 box
            boxmin = (boxmin + box9min) * 0.5;
            boxmax = (boxmax + box9max) * 0.5;
        }

        if (materialConstants_boxType == BOX_TYPE_VARIANCE ||
                materialConstants_boxType == BOX_TYPE_AABB_VARIANCE) {
            // "An Excursion in Temporal Supersampling" by Marco Salvi
            highp vec3 m0 = s[4];// conversion to highp
            highp vec3 m1 = m0 * m0;
            // we use only 5 samples instead of all 9
            for (int i = 1; i < 9; i+=2) {
                highp vec3 c = s[i];// conversion to highp
                m0 += c;
                m1 += c * c;
            }
            highp vec3 a0 = m0 * (1.0 / 5.0);
            highp vec3 a1 = m1 * (1.0 / 5.0);
            highp vec3 sigma = sqrt(a1 - a0 * a0);
            if (materialConstants_boxType == BOX_TYPE_VARIANCE) {
                boxmin = a0 - materialConstants_varianceGamma * sigma;
                boxmax = a0 + materialConstants_varianceGamma * sigma;
            } else {
                // intersect both bounding boxes
                boxmin = max(boxmin, a0 - materialConstants_varianceGamma * sigma);
                boxmax = min(boxmax, a0 + materialConstants_varianceGamma * sigma);
            }
        }
        // history clamping
        history = clipToBox(materialConstants_boxClipping, boxmin, boxmax, filtered, history);
    }

    float lumaColor   = luma(filtered.rgb);
    float lumaHistory = luma(history.rgb);

    float alpha = materialParams.alpha;
    if (materialConstants_preventFlickering) {
        // [Lottes] prevents flickering by modulating the blend weight by the difference in luma
        float diff = 1.0 - abs(lumaColor - lumaHistory) / (0.001 + max(lumaColor, lumaHistory));
        alpha *= diff * diff;
    }

    // tonemapping for handling HDR
    filtered.rgb *= 1.0 / (1.0 + lumaColor);
    history.rgb  *= 1.0 / (1.0 + lumaHistory);

    // combine history and current frame
    vec4 result = mix(history, filtered, alpha);

    // untonemap result
    result.rgb *= 1.0 / (1.0 - luma(result.rgb));

    if (materialConstants_useYCoCg) {
        result.rgb = YCoCg_RGB(result.rgb);
    }

#if POST_PROCESS_OPAQUE
    // kill the work performed above
    result.a = 1.0;
#endif

    // store result (which will becomes new history)
    postProcess.color = result;
}

}
