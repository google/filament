material {
    name : sao,
    parameters : [
        {
            type : sampler2d,
            name : depth,
            precision: high
        },
        {
            type : float4,
            name : resolution
        },
        {
            type : float,
            name : radius
        },
        {
            type : float,
            name : invRadiusSquared
        },
        {
            type : float,
            name : peak2
        },
        {
            type : float,
            name : projectionScaleRadius
        },
        {
            type : float,
            name : bias
        },
        {
            type : float,
            name : power
        },
        {
            type : float,
            name : intensity
        },
        {
            type : int,
            name : maxLevel
        }
    ],
    variables : [
         vertex
    ],
    domain : postprocess,
    depthWrite : false,
    depthCulling : true
}

vertex {
    void postProcessVertex(inout PostProcessVertexInputs postProcess) {
        postProcess.vertex.xy = postProcess.normalizedUV;
    }
}

fragment {
    const float kSpiralSampleCount = 7.0;
    const float kSpiralTurns = 5.0;
    const float kLog2LodRate = 3.0;

    vec2 sq(const vec2 a) {
        return a * a;
    }

    // remaps to -1 and 1, repeating
    float reduce(highp float x) {
        return fract(0.5 * x + 0.5) * 2.0 - 1.0;
    }

    // very crude and fast sin/cos approximation
    vec2 fast_cossin(highp float x) {
        x *= 1.0/PI;
        vec2 a = vec2(reduce(x + 0.5), reduce(x));
        vec2 xn = sq(a * 2.0 + 1.0) - 1.0;
        vec2 xp = 1.0 - sq(a * 2.0 - 1.0);
        return vec2(a.x < 0.0 ? xn.x : xp.x, a.y < 0.0 ? xn.y : xp.y);
    }

    // random number between 0 and 1, using interleaved gradient noise
    float random(vec2 w) {
        const vec3 m = vec3(0.06711056, 0.00583715, 52.9829189);
        return fract(m.z * fract(dot(w.xy, m.xy)));
    }

    highp float linearizeDepth(highp float depth) {
        // Our far plane is at infinity, which causes a division by zero below, which in turn
        // causes some issues on some GPU. We workaround it by replacing "infinity" by the closest
        // value representable in  a 24 bit depth buffer.
        const float preventDiv0 = -1.0 / 16777216.0;
        highp mat4 projection = getClipFromViewMatrix();
        highp float z = depth * 2.0 - 1.0; // depth in clip space
        return -projection[3].z / min(preventDiv0, z + projection[2].z);
    }

    highp float sampleDepthLinear(const vec2 uv, float level) {
        return linearizeDepth(textureLod(materialParams_depth, uv, level).r);
    }

    highp vec3 computeViewSpacePositionFromDepth(vec2 p, highp float linearDepth) {
        p = p * 2.0 - 1.0; // to clip space
        highp mat4 invProjection = getViewFromClipMatrix();
        p.x *= invProjection[0].x;
        p.y *= invProjection[1].y;
        return vec3(p * -linearDepth, linearDepth);
    }

    // compute normals using derivatives, which essentially results in half-resolution normals
    // this creates arifacts around geometry edges.
    // Moreover, this seems a lot slower (measured on Pixel4), which I find curious.
    highp vec3 computeViewSpaceNormal(const highp vec3 position) {
        return normalize(cross(dFdx(position), dFdy(position)));
    }

    // compute normals directly from the depth texture, resulting in full resolution normals
    highp vec3 computeViewSpaceNormal(const highp vec3 position, const vec2 uv) {
        vec2 uvdx = uv + vec2(materialParams.resolution.z, 0.0);
        vec2 uvdy = uv + vec2(0.0, materialParams.resolution.w);
        highp vec3 px = computeViewSpacePositionFromDepth(uvdx, sampleDepthLinear(uvdx, 0.0));
        highp vec3 py = computeViewSpacePositionFromDepth(uvdy, sampleDepthLinear(uvdy, 0.0));
        highp vec3 dpdx = px - position;
        highp vec3 dpdy = py - position;
        return normalize(cross(dpdx, dpdy));
    }

    // Ambient Occlusion, largely inspired from:
    // "The Alchemy Screen-Space Ambient Obscurance Algorithm" by Morgan McGuire
    // "Scalable Ambient Obscurance" by Morgan McGuire, Michael Mara and David Luebke

    vec3 tapLocation(float i, const float noise) {
        // note: with this formulation we could precompute the samples in an array
        //       and combine the noise, which would allow is to call sin/cos only
        //       once per pixel.
        float radius = (i + 0.5) * (1.0 / kSpiralSampleCount);
        float angle = (radius * kSpiralTurns + noise) * (2.0 * PI);
        return vec3(fast_cossin(angle), radius);
    }

    void computeAmbientOcclusionSAO(inout float occlusion,
            float i, float ssDiskRadius, const vec2 ssOrigin,
            const highp vec3 origin, const vec3 normal, const float noise) {

        vec3 tap = tapLocation(i, noise);
        float ssRadius = max(1.0, tap.z * ssDiskRadius); // at least 1 pixel screen-space radius

        vec2 uvSamplePos = ssOrigin + vec2(ssRadius * tap.xy) * materialParams.resolution.zw;

        float level = clamp(floor(log2(ssRadius)) - kLog2LodRate, 0.0, float(materialParams.maxLevel));
        highp float occlusionDepth = sampleDepthLinear(uvSamplePos, level);
        highp vec3 p = computeViewSpacePositionFromDepth(uvSamplePos, occlusionDepth);

        // now we have the sample, compute AO
        vec3 v = p - origin;        // sample vector
        float vv = dot(v, v);       // squared distance
        float vn = dot(v, normal);  // distance * cos(v, normal)
        float w = saturate(1.0 - vv * materialParams.invRadiusSquared);
        occlusion += w * max(0.0, vn + origin.z * materialParams.bias) / (vv + materialParams.peak2);
    }

    void postProcess(inout PostProcessInputs postProcess) {
        highp vec2 uv = variable_vertex.xy; // interpolated to pixel center

        highp float depth = sampleDepthLinear(uv, 0.0);
        highp vec3 origin = computeViewSpacePositionFromDepth(uv, depth);

        vec3 normal = computeViewSpaceNormal(origin, uv);
        float noise = random(gl_FragCoord.xy);

        // Choose the screen-space sample radius
        // proportional to the projected area of the sphere
        float ssDiskRadius = -(materialParams.projectionScaleRadius / origin.z);

        float occlusion = 0.0;
        for (float i = 0.0; i < kSpiralSampleCount; i += 1.0) {
            computeAmbientOcclusionSAO(occlusion, i, ssDiskRadius, uv, origin, normal, noise);
        }

        float ao = max(0.0, 1.0 - occlusion * (materialParams.intensity * (1.0 / kSpiralSampleCount)));
        ao = pow(ao, materialParams.power);

        // Apply a 2x2 bilateral box filter, taking advantage of quad shading. If we were not
        // applying the bilateral filter, this would be equivalent to downsampling the AO buffer
        // using a 2x2 box. Thanks to the bilateral filter, we keep some sharp edges.
        // mod2() below will return either 0.5 or 1.5
        // This assumes full derivatives are supported.
        const float kEdgeDistance = 0.1; // this shouldn't be hardcoded
        ivec2 coords = ivec2(gl_FragCoord.xy);
        ao += (1.0 - step(kEdgeDistance, abs(dFdx(origin.z)))) * dFdx(ao) * (0.5 - float(coords.x & 1));
        ao += (1.0 - step(kEdgeDistance, abs(dFdy(origin.z)))) * dFdy(ao) * (0.5 - float(coords.y & 1));
        postProcess.color.r = ao;
    }
}
